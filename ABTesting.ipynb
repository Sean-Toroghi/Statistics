{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "M3jmzLRTAQ5_"
      ],
      "authorship_tag": "ABX9TyPwOOrrGWUi67GoTYxzBjNQ"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Distilled AB Testing</h1>"
      ],
      "metadata": {
        "id": "FchbszUtpSTx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "__References__\n",
        "\n",
        "- [Trustworthy Online Controlled Experiments: A Practical Guide to A/B Testing](https://www.cambridge.org/core/books/trustworthy-online-controlled-experiments/D97B26382EB0EB2DC2019A7A7B518F59)\n",
        "- Udemy AB testing cource\n",
        "- [Product plan](https://www.productplan.com/glossary/aarrr-framework/)\n",
        "- [Medium article 2023](https://simran-pm.medium.com/heart-aarrr-frameworks-in-product-management-7596b6c717de)\n",
        "- Practical statistics for data scientists [link](https://www.oreilly.com/library/view/practical-statistics-for/9781491952955/)\n"
      ],
      "metadata": {
        "id": "rQvBH6sbpYyN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summary of AB testing"
      ],
      "metadata": {
        "id": "eMvQRzRy3Bz-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "__Overview__\n",
        "\n",
        "In nutshell, based on what I have read about AB testing from a range of resources (refer to reference section), AB testing is a about design, conduct, and inference statistical analysis about a product/service. It gors through the same steps I normalyy would need to do for a statistical analysis on population and samples.\n",
        "\n",
        "In AB testng, the goal is to find the impact/effect of applying a change to the system. This change could be defined in a range of applications, from implementing a new feature to modify a section of a website. Similar to statistical analysis, desing of an AB testing includes carefully select sample size that represent the target population, define a confidence and error thresholds, and derive a desicion or identify causality based on the statiscal analysis method (with a high probability).\n",
        "\n",
        "AB testing also follows t\n",
        "Some keywords:\n",
        "- Variants: different versions of a product/serice\n",
        "- 2 varient test is called A/B test, which consists of controll and test groups\n",
        "- in case of more than 2 varients, the test is called A/B/N test\n",
        "-A/B test also called randomized controlled experiment, control experiment, split test, or even sometime A/B/N test. They all refer to the same concept/method.\n",
        "\n",
        "\n",
        "\n",
        "__Steps of AB testing__\n",
        "- pre-requisits\n",
        "  - Define key metrics (also called overal evaluation criterions (OCT))\n",
        "  - Define feasible changes, not to hard to implement that evan if the positive outcome could not justify the implementation.\n",
        "  - could access to adequate randomization units for each varient. Otherwise the outcome could not be generalized to the population. Basically define sample size according the design requirements (confidence level, max variance, ...)\n",
        "\n",
        "- experiment design\n",
        "  - define a non-bias target population to sample from\n",
        "  - define sample size that could deliver the needed statistical power\n",
        "  - define duration while considering seasonality, primary and novelty effect, day of the week/time of the day/holidays,\n",
        "- run the experiment and collect data\n",
        "  - this step includes setting proper instrument to log data, use third party or utilize company's own platform if available to run the experoment.\n",
        "- results/analysis\n",
        "  - run EDA\n",
        "  - apply required pre-processing steps\n",
        "  - run analysis method on data to derive inference/prediction or other iformation from the collected data\n",
        "  - run sanity checks\n",
        "  - identify root causes for any issue with data during validation and sanity check process and derive lesson learned\n",
        "  - based on the results make desicions, cosidering the tradeoffs btw used metrics, cost of implementing the change, consider opportunity costs, compare benefits with costs based on pre-defined practical signification boundary.\n",
        "\n",
        "- post-experiment monitoring\n",
        "  - monitor the effect of making change, since in many cases long- and short-term effects could be significantly different.\n",
        "  - Also derive lesson learned for future implementation / decision makings\n",
        "\n",
        "---\n",
        "\n",
        "__Crack A/B testing problems__\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IM5-Uy3s3ENk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A/B testing metrics"
      ],
      "metadata": {
        "id": "E01c2V5hAKfy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "__Criterio for selecting a metric__\n",
        "- Measurable within the experiment timeframe.\n",
        "- Attributable to the change in the product/feature.\n",
        "- Sensitive enough to detect changes that matter in a timely fashion.\n",
        "\n",
        "__Also metric needs to be satable and simple.__ It needs to be simple, so everyone could understand it and broadly acceptable by stakeholders. A sofisticated metric that no-one desire to put time to understand for a marginal gain does not traslate to a winning approach. Furthermore, a stable metric does not require an update or modification every time we run the test.\n",
        "\n",
        "Two types of metrics\n",
        "- goal metrics (long term, less sensitive, slow move)\n",
        "- driver metrics (short-term, higher sensitivity, fast move)\n",
        "\n"
      ],
      "metadata": {
        "id": "8yunIJQ09YYl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Driver metrics"
      ],
      "metadata": {
        "id": "M3jmzLRTAQ5_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "__Driver metrics__\n",
        "\n",
        "These metrics reflect hypotheses on the drivers of success and indicates we are moving in the right direction toward the goal metrics. They are actionable and resistant to gaming .Some business goal related driver metrics are growth, revenue, and engagement.\n",
        "\n",
        "Design a driver metric:\n",
        "\n",
        "  Mainly we follow user funnel approach for designing a driver metric. An example of this approch is AARRR (acquisition, activation, retention, referral, and revenue) framework, or HEART (happiness, engagement, adoption, retention, and task Success) framework.\n",
        "\n",
        "---\n",
        "\n",
        "### User funnel\n",
        "A user funnel is a pathway that a user takes when they go from lead to paying customers and beyond. It traces the customer journey from first recognizing they need a solution to a problem, becoming aware of your brand, and their entire sales process. It also covers their behavior post-purchase.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "### AARRR framework (also known as Pirate Metrcis framework).\n",
        "This framework was invented by Dave McClure in 2007. It consists of five user-behavior metrics that product-led growth businesses should be tracking.\n",
        "\n",
        "__Step 1: Identify the metrics__\n",
        "\n",
        "At this step we define the five metrics:\n",
        "- Acquisition (or awareness): How are people discovering our product or ompany?\n",
        "\n",
        "  It includes all the channels a company utilizes to introduce its product/service.\n",
        "\n",
        "- Activation: Are these people taking the actions we want them to?\n",
        "\n",
        "  It investigate if customers/users take a desire action, such as sign up for a free trial.\n",
        "\n",
        "- Retention: Are our activated users continuing to engage with the roduct?\n",
        "\n",
        "  It consists of monitor those who took the previous step, and see if they continue using the product/service. An example is returning product, or sign up for permanent membership after the free trial period.\n",
        "\n",
        "- Referral: Do users like the product enough to tell others about it?\n",
        "  \n",
        "  Whether the customers take further action to introduce the product/service to others. Example is referal contest or emails with promotions embeddd.\n",
        "\n",
        "- Revenue: Are our personas willing to pay for this product?\n",
        "\n",
        "  In this section we investigate if the cost of performing all the above action plus making the product/service is turned into revenue. Examples are computing minimum revenue, or break-even revenue.\n",
        "\n",
        "__Step 2: setup process to track and analyze the metrics__\n",
        "\n",
        "After defining the metrics, we need to implement tools to collect required data. An example is KISSmetrics. Depending on company resouces, this could be done within the company of employ a third party.\n",
        "\n",
        "At this stage, we also need to determine an estimated dollar amount for each category of user behavior to evaluate effectiveness of product management and marketing initiatives.\n",
        "\n",
        "__Step 3: RUN A/B testing__\n",
        "\n",
        "Here we employ a range of A/B testing, and see if we could improve each of the five stages of the AARRR framework.\n",
        "\n",
        "__Step 4: improve according to the results__\n",
        "\n",
        "At this poind, based on the outcome of the tests ran in the previous step, we implement the best approach and adjust the marketing or product feature accordingly.\n",
        "\n",
        "---\n",
        "\n",
        "### HEART framework\n",
        "\n",
        "The HEART framework is a methodology to improve the user experience (UX) of software. It was designed at Google by Kerry Rodden. The framework helps a company evaluate any aspect of its user experience according to five user-centered metrics. It consists of five metrics:\n",
        "1. Happiness: measures how satisfied users are with the product.\n",
        "2. Engagement: measures how users interact with the product.\n",
        "3. Adoption: measures how many users adopt the product.\n",
        "4. Retention: measures how long users stay with the product.\n",
        "5. Task success: measures how well users are able to complete their tasks\n",
        "\n",
        "For each metric, we first define the followings:\n",
        "- goals: broad objectives.\n",
        "- signals: indicators that show progress toward the goals\n",
        "- metrics: consist of quantifiable data points indicating success or failure.\n",
        "\n",
        "__Example:__\n",
        "- Hapiness:\n",
        "  - Goals: increasing user satisfaction scores, reducing churn, or increasing the number of positive reviews.\n",
        "  - Signals: user feedback, survey results, or social media mentions.\n",
        "  - Metrics: Net Promoter Score (NPS), customer satisfaction (CSAT) scores, or churn rate.\n",
        "- Engagement:\n",
        "  - Goals: increasing the number of active users, increasing the average session length, or increasing the number of page views.\n",
        "  - Signals: user behavior data, such as clickstream data or session recordings.\n",
        "  - Metrics: active users, average session length, or page views per session.\n",
        "- Adoption:\n",
        "  - Goals: increasing the number of new users, increasing the number of returning users or increasing the number of users who complete a specific task.\n",
        "  - Signals: user behaviour data, such as the number of downloads or registrations.\n",
        "  - Metrics: new users, returning users, or task completion rates.\n",
        "- Retention:\n",
        "  - Goals: increasing the number of active users, increasing the average customer lifetime value (CLV), or reducing the churn rate.\n",
        "  - Signals: user behaviour data, such as the number of days since the last login or the number of times a user has opened the app.\n",
        "  - Metrics: active users, CLV, or churn rate.\n",
        "- Task success:\n",
        "  - Goals: increasing the number of tasks completed, reducing the number of errors, or increasing the user experience (UX) score.\n",
        "  - Signals: user behavior data, such as the number of tasks completed or the number of errors made.\n",
        "  - Metrics: tasks completed, errors made, or a UX score."
      ],
      "metadata": {
        "id": "N9MM87I8ASlF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Guardrail metrics"
      ],
      "metadata": {
        "id": "akYVDV69ATmD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Guardrail metrics (counter metrics) are employed to make sure we move to sucess without violating constrains.\n",
        "\n",
        "Some examples:\n",
        "- error log\n",
        "- number of crashes\n",
        "- revenue per user\n"
      ],
      "metadata": {
        "id": "L7B2yN_WAV2d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trust-related metrics"
      ],
      "metadata": {
        "id": "AXGkvoc5CXy6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "They assess the trustworthiness and internal validity of experiment results.\n",
        "\n",
        "Examples:\n",
        "- have the same Sample Ratio Mismatch (SRM) guardrail across control and teratment\n",
        "\n"
      ],
      "metadata": {
        "id": "uD-2J96TCaNb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Randomization units"
      ],
      "metadata": {
        "id": "SFjU3IqzCzHQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "General consideration\n",
        "- consistent user experience\n",
        "- variability\n",
        "- ethical considerations\n",
        "\n",
        "\n",
        "__Choices for randomization units__\n",
        "1. account-based\n",
        "2. cookie-based\n",
        "3. session-based\n",
        "4. IP-based\n",
        "5. device-vased\n",
        "\n",
        "\n",
        "__Randomization unit vs analyzes unit__: randomization unit is similar or coarser than analysis unit\n",
        "\n",
        "Example: randoimize unit person, analyze unit page visit\n",
        "\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "EV5E0og8C062"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Choosing target population"
      ],
      "metadata": {
        "id": "kfwXF2e4EmQq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "aULMvpv_EojA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "__Computing sample size__\n",
        "\n",
        "The most common approach is two-sampled t-test.\n",
        "\n",
        "$\\begin{cases}  \\text{null hypothesis} H_0: \\mu_c = \\mu_t \\\\ \\text{alternative hypothesis} H_1:\\mu_c \\neq \\mu_t \\end{cases}$\n",
        "\n",
        "__Choosing sample size__ depends on the following parameters:\n",
        "1. significance level (type I error)\n",
        "2. statistical power (Type II error)\n",
        "3. variance\n",
        "4. minimally detectable error\n",
        "\n",
        "\n",
        "$$n = \\frac{(\\sigma^2_t + \\sigma^2_c) (Z_{1-\\alpha/2} + Z_{1-\\beta} )^2}{\\delta^2}$$\n",
        "\n",
        "Some most common values for the parameters:\n",
        "- $\\alpha = 0.05$\n",
        "- $\\beta = 0.2$\n",
        "- $Z_{1-\\alpha/2} = 1.96$\n",
        "- $ Z_{1-\\beta} = 0.84$\n",
        "\n",
        "Assuming we have same size treatment and control buckets:\n",
        " $$n = \\frac{16\\sigma^2}{\\delta^2}$$\n",
        " where\n",
        " - $\\sigma^2$ is the Sample variance of the difference between the Treatment and the Control (for ratio metrics, the maximum variance is 0.25)\n",
        " - $\\delta$ is practical significance (Minimum detectable effect), determined among multiple stakeholders.\n",
        "\n",
        " ---\n",
        "\n",
        " __Sanity check methods__\n",
        " 1. A/A test: it needs to be run before system is used in the application\n",
        " 2. Z-test or t-test\n",
        " 3. Chi-squared test\n"
      ],
      "metadata": {
        "id": "zppOBLjwE0CC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trustworthy Online Controlled Experiments"
      ],
      "metadata": {
        "id": "HgOcO6hyxz_3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BPL-dJbdpP-N"
      },
      "outputs": [],
      "source": []
    }
  ]
}